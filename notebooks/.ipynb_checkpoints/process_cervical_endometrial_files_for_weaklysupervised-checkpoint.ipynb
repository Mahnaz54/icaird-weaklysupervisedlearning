{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "from xlrd import *\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mahnaz/Desktop/endometrial_new_slide_labels/excel_files'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = '/home/mahnaz/Desktop/iCAIRD_new_slide_labels'\n",
    "excel_files_dir  = os.path.join(root + '/excel_files')\n",
    "csv_files_dir = os.path.join(root + '/csv_files')\n",
    "\n",
    "excel_files_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mahnaz/Desktop/endometrial_new_slide_labels/csv_files'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_files_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n"
     ]
    }
   ],
   "source": [
    "filenames = os.listdir(excel_files_dir)\n",
    "for filename in filenames:\n",
    "    #print('processing {}'.format(filename))\n",
    "    if '.xls' in filename:\n",
    "        read_file = pd.read_excel( excel_files_dir + '/'+ filename)\n",
    "        read_file.to_csv (csv_files_dir +'/' +filename.split('.')[0] + '.csv', index = None, header=True, encoding = 'utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are total 3649 cervical and endometrial files\n"
     ]
    }
   ],
   "source": [
    "all_filenames = os.listdir(csv_files_dir)\n",
    "#combine all files in the list\n",
    "all_files = pd.concat([pd.read_csv(csv_files_dir+ '/'+ f) for f in all_filenames ])\n",
    "print('There are total {} cervical and endometrial files'.format(len(all_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are total 1976 cervical files before deleting excluded files\n",
      "There are total 1673 endometriall files before deleting excluded files\n"
     ]
    }
   ],
   "source": [
    "#sperate endometrial and cervical files\n",
    "total_cervical = all_files[all_files.SampleType =='CX']\n",
    "total_endometrial = all_files[all_files.SampleType =='EN']\n",
    "print('There are total {} cervical files before deleting excluded files'.format(len(total_cervical)))\n",
    "print('There are total {} endometriall files before deleting excluded files'.format(len(total_endometrial)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 cervical files are excluded\n",
      "Total number of cervical train slides after exclusion = 1930\n"
     ]
    }
   ],
   "source": [
    "#filter out the excluded files (cervical)\n",
    "excluded_cervical =total_cervical[total_cervical.ExcludedFromAnnotation==1]\n",
    "excluded_cervical.to_csv(root+ '/' +'excluded_cervical_files.csv', index= False)\n",
    "print('{} cervical files are excluded'.format(len(excluded_cervical)))\n",
    "cervical_train = total_cervical[total_cervical.ExcludedFromAnnotation==0]\n",
    "cervical_train = cervical_train.sort_values(by ='ImageName')\n",
    "print('Total number of cervical train slides after exclusion = {}'.format(len(cervical_train)))\n",
    "#cervical_train.to_csv(root + '/' + 'cervical_train.csv', index = None, encoding = 'utf-8-sig')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cervical Train Set Main Categories Count:\n",
      " low_grade              586\n",
      "high_grade             490\n",
      "normal_inflammation    452\n",
      "malignant              402\n",
      "Name: Cat, dtype: int64\n",
      "\n",
      "\n",
      "Cervical Train Set SubCategories Count:\n",
      " normal_inflammation    452\n",
      "hpv                    318\n",
      "cin1                   268\n",
      "cin3                   248\n",
      "cin2                   242\n",
      "squamous_carcinoma     212\n",
      "adenocarcinoma          73\n",
      "cgin                    70\n",
      "other                   47\n",
      "Name: SubCat, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#cervical_train = pd.read_csv('cervical_train.csv')\n",
    "\n",
    "cervical_train['Cat'] = cervical_train['Cat'].str.lower()\n",
    "cervical_train['SubCat'] = cervical_train['SubCat'].str.lower()\n",
    "\n",
    "cervical_train['SubCat'] = cervical_train['SubCat'].str.replace('/', '_')\n",
    "cervical_train['Cat'] = cervical_train['Cat'].str.replace('/','_')\n",
    "cervical_train['Cat'] = cervical_train['Cat'].str.replace(' ','_')\n",
    "cervical_train['SubCat'] = cervical_train['SubCat'].str.replace('cin 1', 'cin1')\n",
    "cervical_train['SubCat'] = cervical_train['SubCat'].str.replace('cin 2', 'cin2')\n",
    "cervical_train['SubCat'] = cervical_train['SubCat'].str.replace('cin 3', 'cin3')\n",
    "cervical_train['SubCat'] = cervical_train['SubCat'].str.replace(' ', '_')\n",
    "\n",
    "print('Cervical Train Set Main Categories Count:\\n', cervical_train['Cat'].value_counts())\n",
    "print('\\n')\n",
    "print('Cervical Train Set SubCategories Count:\\n', cervical_train['SubCat'].value_counts())\n",
    "\n",
    "cervical_train = cervical_train.sort_values(by=['AnnotationBatch','ImageName'])\n",
    "\n",
    "cervical_clean = cervical_train[['SampleID','ImageName','Cat']]\n",
    "cervical_clean = cervical_clean.rename(columns={'SampleID':'case_id', 'ImageName':'slide_id','Cat':'label'})\n",
    "cervical_clean.to_csv('cervical_clean.csv')\n",
    "\n",
    "\n",
    "df = cervical_clean['slide_id']+'.isyntax'\n",
    "df = df.sort_values()\n",
    "#df.to_csv('Cervical_ImageNames.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16  endometrial files are excluded\n",
      "Total number of endometrial train slides after exclusion = 1657\n",
      "Endomerial Data main category counts:\n",
      " other_benign    1066\n",
      "malignant        488\n",
      "insufficient     103\n",
      "Name: Cat, dtype: int64\n",
      "\n",
      "\n",
      "Endomerial Data sub category counts:\n",
      " adenocarcinoma          287\n",
      "proliferative           223\n",
      "secretory               221\n",
      "innactive               212\n",
      "hormonal                202\n",
      "menstrual               200\n",
      "hyperplaysia            134\n",
      "insufficient            109\n",
      "carcinosarcoma           48\n",
      "sarcoma                  14\n",
      "other                     6\n",
      "atypical hyperplasia      1\n",
      "Name: SubCat, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "excluded_endo = total_endometrial[total_endometrial.ExcludedFromAnnotation==1]\n",
    "excluded_endo.to_csv(root+ '/' +'excluded_endo_files.csv', index= False)\n",
    "print('{}  endometrial files are excluded'.format(len(excluded_endo)))\n",
    "endometrial_train = total_endometrial[total_endometrial.ExcludedFromAnnotation==0]\n",
    "endo_train = endometrial_train.sort_values(by ='ImageName')\n",
    "print('Total number of endometrial train slides after exclusion = {}'.format(len(endometrial_train)))\n",
    "#endo_train.to_csv('endometrial_train.csv', index = None, encoding ='utf-8-sig')\n",
    "\n",
    "endo_train['Cat'] = endo_train['Cat'].str.lower()\n",
    "endo_train['SubCat'] = endo_train['SubCat'].str.lower()\n",
    "\n",
    "\n",
    "endo_train['SubCat'] = endo_train['SubCat'].str.replace('/', '_')\n",
    "endo_train['Cat'] = endo_train['Cat'].str.replace('/','_')\n",
    "\n",
    "endo_train['SubCat'] = endo_train['SubCat'].str.replace('hyperplasia with atypia', 'hyperplaysia')\n",
    "endo_train['SubCat'] = endo_train['SubCat'].str.replace('innactive_atrophic', 'innactive')\n",
    "\n",
    "print('Endomerial Data main category counts:\\n',endo_train['Cat'].value_counts())\n",
    "print('\\n')\n",
    "print('Endomerial Data sub category counts:\\n',endo_train['SubCat'].value_counts())\n",
    "\n",
    "endometrial = endo_train.sort_values(by=['AnnotationBatch','ImageName'])\n",
    "\n",
    "endo_clean = endometrial_train[['SampleID','ImageName','Cat']]\n",
    "endo_clean = endo_clean.rename(columns={'SampleID':'case_id', 'ImageName':'slide_id','Cat':'label'})\n",
    "endo_clean.to_csv('endometrial_clean.csv')\n",
    "\n",
    "\n",
    "df1 = endo_clean['slide_id']+'.isyntax'\n",
    "df1 = df1.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wsi-weaklysupervisedlearning-isyntax",
   "language": "python",
   "name": "wsi-weaklysupervisedlearning-isyntax"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
