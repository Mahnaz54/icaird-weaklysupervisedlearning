{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "from xlrd import *\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n",
      "There are total 3849 cervical and endometrial files\n"
     ]
    }
   ],
   "source": [
    "#READ CEXCEL FILES AND CONVERT THEM TO CSV FILES AND COMBINE THEM TO ONE FILE\n",
    "root = '/home/mahnaz/Desktop/iCAIRD_new_slide_labels'\n",
    "excel_files_dir  = os.path.join(root + '/excel_files')\n",
    "csv_files_dir = os.path.join(root + '/csv_files')\n",
    "\n",
    "filenames = os.listdir(excel_files_dir)\n",
    "for filename in filenames:\n",
    "    #print('processing {}'.format(filename))\n",
    "    if '.xls' in filename:\n",
    "        read_file = pd.read_excel( excel_files_dir + '/'+ filename)\n",
    "        read_file.to_csv (csv_files_dir +'/' +filename.split('.')[0] + '.csv', index = None, header=True, encoding = 'utf-8-sig')\n",
    "        \n",
    "all_filenames = os.listdir(csv_files_dir)\n",
    "#combine all files in the list\n",
    "all_files = pd.concat([pd.read_csv(csv_files_dir+ '/'+ f) for f in all_filenames ])\n",
    "print('There are total {} cervical and endometrial files'.format(len(all_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of endometrial slides after exclusion = 1854\n"
     ]
    }
   ],
   "source": [
    "endometrial = all_files[(all_files.SampleType =='EN') & (all_files.ExcludedFromAnnotation==0)]\n",
    "print('Total number of endometrial slides after exclusion = {}'.format(len(endometrial)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>BiobankID</th>\n",
       "      <th>SampleType</th>\n",
       "      <th>Microtome</th>\n",
       "      <th>Thickness</th>\n",
       "      <th>Category</th>\n",
       "      <th>SubCategory</th>\n",
       "      <th>StainingSiteID</th>\n",
       "      <th>StainingProtocol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IC-EN-00001-01.isyntax</td>\n",
       "      <td>IC-EN-00001</td>\n",
       "      <td>EN</td>\n",
       "      <td>2</td>\n",
       "      <td>4µm</td>\n",
       "      <td>other_benign</td>\n",
       "      <td>Menstrual</td>\n",
       "      <td>3</td>\n",
       "      <td>paeds protocol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IC-EN-00003-01.isyntax</td>\n",
       "      <td>IC-EN-00003</td>\n",
       "      <td>EN</td>\n",
       "      <td>1</td>\n",
       "      <td>3µm</td>\n",
       "      <td>other_benign</td>\n",
       "      <td>Secretory</td>\n",
       "      <td>3</td>\n",
       "      <td>paeds protocol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IC-EN-00004-01.isyntax</td>\n",
       "      <td>IC-EN-00004</td>\n",
       "      <td>EN</td>\n",
       "      <td>1</td>\n",
       "      <td>3µm</td>\n",
       "      <td>other_benign</td>\n",
       "      <td>Secretory</td>\n",
       "      <td>1</td>\n",
       "      <td>routine H&amp;E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IC-EN-00007-01.isyntax</td>\n",
       "      <td>IC-EN-00007</td>\n",
       "      <td>EN</td>\n",
       "      <td>2</td>\n",
       "      <td>4µm</td>\n",
       "      <td>malignant</td>\n",
       "      <td>Adenocarcinoma</td>\n",
       "      <td>2</td>\n",
       "      <td>routine H&amp;E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IC-EN-00009-01.isyntax</td>\n",
       "      <td>IC-EN-00009</td>\n",
       "      <td>EN</td>\n",
       "      <td>3</td>\n",
       "      <td>3µm</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>Insufficient</td>\n",
       "      <td>5</td>\n",
       "      <td>neuro (hand staining protocol)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Filename    BiobankID SampleType  Microtome Thickness  \\\n",
       "0  IC-EN-00001-01.isyntax  IC-EN-00001         EN          2       4µm   \n",
       "1  IC-EN-00003-01.isyntax  IC-EN-00003         EN          1       3µm   \n",
       "2  IC-EN-00004-01.isyntax  IC-EN-00004         EN          1       3µm   \n",
       "3  IC-EN-00007-01.isyntax  IC-EN-00007         EN          2       4µm   \n",
       "4  IC-EN-00009-01.isyntax  IC-EN-00009         EN          3       3µm   \n",
       "\n",
       "       Category     SubCategory  StainingSiteID  \\\n",
       "0  other_benign       Menstrual               3   \n",
       "1  other_benign       Secretory               3   \n",
       "2  other_benign       Secretory               1   \n",
       "3     malignant  Adenocarcinoma               2   \n",
       "4  insufficient    Insufficient               5   \n",
       "\n",
       "                 StainingProtocol  \n",
       "0                  paeds protocol  \n",
       "1                  paeds protocol  \n",
       "2                     routine H&E  \n",
       "3                     routine H&E  \n",
       "4  neuro (hand staining protocol)  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endometrial = endometrial.sort_values(by=['AnnotationBatch','Filename'])\n",
    "# endometrial = endometrial.rename(columns={'SampleID':'BiobankID', 'Cat':'Category', 'SubCat':'SubCategory'})\n",
    "endometrial['Category'] = endometrial['Category'].str.lower()\n",
    "endometrial['SubCat'] = endometrial['SubCategory'].str.lower()\n",
    "\n",
    "\n",
    "endometrial['SubCategory'] = endometrial['SubCategory'].str.replace('/', '_')\n",
    "endometrial['Category'] = endometrial['Category'].str.replace('/','_')\n",
    "\n",
    "endometrial['SubCategory'] = endometrial['SubCategory'].str.replace('hyperplasia with atypia', 'hyperplaysia')\n",
    "endometrial['SubCatgory'] = endometrial['SubCategory'].str.replace('innactive_atrophic', 'innactive')\n",
    "endometrial = endometrial[['Filename','BiobankID', 'SampleType','Microtome','Thickness', 'Category', 'SubCategory', 'StainingSiteID', 'StainingProtocol']]\n",
    "endometrial['Filename'] = endometrial['Filename'] +'.isyntax'\n",
    "endometrial = endometrial.reset_index(drop=True)\n",
    "endometrial.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "endometrial Set Main Categories Count:\n",
      " other_benign    1187\n",
      "malignant        551\n",
      "insufficient     116\n",
      "Name: Category, dtype: int64\n",
      "\n",
      "\n",
      "endometrial  Set SubCategories Count:\n",
      " Adenocarcinoma             319\n",
      "Secretory                  250\n",
      "Proliferative              248\n",
      "Innactive_atrophic         233\n",
      "Hormonal                   224\n",
      "Menstrual                  223\n",
      "Hyperplasia with atypia    155\n",
      "Insufficient               123\n",
      "Carcinosarcoma              56\n",
      "Sarcoma                     15\n",
      "Other                        7\n",
      "Atypical Hyperplasia         1\n",
      "Name: SubCategory, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('endometrial Set  Categories Count:\\n', endometrial['Category'].value_counts())\n",
    "print('\\n')\n",
    "print('endometrial  Set SubCategories Count:\\n', endometrial['SubCategory'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endometrial_original = pd.read_csv(os.path.join(root + '/iCAIRD_Endometrial_Data.csv'))\n",
    "endometrial_original = endometrial_original.sort_values(by=['Filename'])\n",
    "endometrial_original = endometrial_original.rename(columns={'subCategory':'SubCategory'})\n",
    "endometrial_original = endometrial_original.reset_index(drop=True)\n",
    "print(len(endometrial_original))\n",
    "endometrial_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blood_mucus  = pd.read_csv(os.path.join(root + 'bloodm_training.csv')\n",
    "blood_mucus_names = blood_mucus['ImageName']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endometrial_original_df = endometrial_original[['Filename','train/valid/test']]\n",
    "merged_df = pd.merge(endometrial_original_df,endometrial, how ='left')\n",
    "merged_df = merged_df.dropna()\n",
    "merged_df = merged_df.reset_index(drop=True)\n",
    "merged_df = merged_df [['Filename','BiobankID', 'SampleType','Microtome','Thickness', 'Category', 'SubCategory', 'StainingSiteID', 'StainingProtocol','train/valid/test']]\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endometrial_train = merged_df[merged_df['train/valid/test'] == 'train']\n",
    "endometrial_test = merged_df[merged_df['train/valid/test'] == 'test']\n",
    "\n",
    "print('Endometrial Train Set before split to train/valid  Main Categories Count:\\n', endometrial_train['Category'].value_counts())\n",
    "print('\\n')\n",
    "print('Endometrial Train Set  before split to train/valid  SubCategories Count:\\n', endometrial_train['SubCategory'].value_counts())\n",
    "print('\\n')\n",
    "print('Endometrial Train Set  before split to train/valid  StainingSiteID Count:\\n', endometrial_train['StainingSiteID'].value_counts())\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "print('\\n')\n",
    "\n",
    "print('Endometrial Test Set Main Categories Count:\\n',endometrial_test['Category'].value_counts())\n",
    "print('\\n')\n",
    "print('Endometrial Tes Set SubCategories Count:\\n', endometrial_test['SubCategory'].value_counts())\n",
    "print('\\n')\n",
    "print('Endometrial Test Set StainingSiteID Count:\\n',endometrial_test['StainingSiteID'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endometrial_train = endometrial_train[~endometrial_train['Filename'].isin(blood_mucus_names)]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, valid = train_test_split(cervical_train, test_size=0.33, random_state=0, stratify=cervical_train[['Category','SubCategory','StainingSiteID']])\n",
    "valid['train/valid/test'] = 'valid'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wsi-weaklysupervisedlearning-isyntax",
   "language": "python",
   "name": "wsi-weaklysupervisedlearning-isyntax"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
